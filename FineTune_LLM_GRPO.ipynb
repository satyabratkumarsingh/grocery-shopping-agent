{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "%%capture\n",
    "import os\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth vllm==0.7.3\n",
    "else:\n",
    "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
    "    !pip install --no-deps unsloth vllm==0.7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Colab Extra Install { display-mode: \"form\" }\n",
    "%%capture\n",
    "import os\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth vllm\n",
    "else:\n",
    "    !pip install --no-deps unsloth vllm\n",
    "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
    "    # Skip restarting message in Colab\n",
    "    import sys, re, requests; modules = list(sys.modules.keys())\n",
    "    for x in modules: sys.modules.pop(x) if \"PIL\" in x or \"google\" in x else None\n",
    "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft \"trl==0.15.2\" triton cut_cross_entropy unsloth_zoo\n",
    "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
    "\n",
    "    # vLLM requirements - vLLM breaks Colab due to reinstalling numpy\n",
    "    f = requests.get(\"https://raw.githubusercontent.com/vllm-project/vllm/refs/heads/main/requirements/common.txt\").content\n",
    "    with open(\"vllm_requirements.txt\", \"wb\") as file:\n",
    "        file.write(re.sub(rb\"(transformers|numpy|xformers)[^\\n]{1,}\\n\", b\"\", f))\n",
    "    !pip install -r vllm_requirements.txt\n",
    "\n",
    "!pip install huggingface_hub\n",
    "!pip install -U langchain langchain-experimental transformers accelerate\n",
    "!pip install -U langgraph\n",
    "!pip install langchain.core\n",
    "! pip install langchain-huggingface\n",
    "! pip install torch\n",
    "! pip install selenium\n",
    "! pip install firecrawl-py\n",
    "! pip install langchain_community\n",
    "! pip install openai\n",
    "! pip install langchain_openai\n",
    "! pip install trl\n",
    "! pip install rapidfuzz\n",
    "! pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Gemma 3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Gemma 3 model\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 4096\n",
    "lora_rank = 64\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/gemma-3-1b-it\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = False,\n",
    "    fast_inference = True, # Enable vLLM fast inference\n",
    "    max_lora_rank = lora_rank,\n",
    "    gpu_memory_utilization = 0.8, # Reduce if out of memory\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,  # Moderate rank for balanced capacity\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"v_proj\", \"up_proj\", \"down_proj\"  # Reduced set for memory efficiency\n",
    "    ],\n",
    "    lora_alpha=32,  # 2 * lora_rank for amplified updates\n",
    "    lora_dropout=0.1,  # Add dropout for regularization\n",
    "    bias=\"none\",  # Default, no bias adaptation\n",
    "    use_gradient_checkpointing=\"unsloth\",  # Keep for long contexts\n",
    "    random_state=3407,  # Keep for reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset which was generated by OpenAI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "# Load dataset\n",
    "try:\n",
    "    dataset = load_dataset(\"json\", data_files=\"products.jsonl\")[\"train\"]\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to load dataset: {e}\")\n",
    "\n",
    "# System prompt\n",
    "system_prompt = \"\"\"You are an expert data extractor.\n",
    "Your task is to extract products and their prices from text.\n",
    "\n",
    "Rules:\n",
    "- If any keyword like \"organic\", \"bio\", or \"eco\" is found in the product description, set \"is_organic\" to \"True\", otherwise set it to \"False\".\n",
    "- Extract all product mentions separately, even if multiple products are in one sentence.\n",
    "- Standardize the \"product\" name by removing only adjectives like \"organic\", \"premium\", \"fresh\", \"natural\", etc., but retain brand names, specific descriptors (e.g., \"Whole\"), and the base product.\n",
    "- Extract the \"price\" as a monetary value (e.g., \"£2.99\"), excluding quantities or other text. Use regex like £\\d+\\.\\d{2} if needed.\n",
    "- Extract \"quantity\" from the product’s packaging description (e.g., \"400g\" for sausages sold in 400g packs).\n",
    "- Strictly avoid unnecessary explanations or text; only return structured data.\n",
    "\n",
    "Ignore:\n",
    "- Any promotional text, ads, filters, or non-product information.\n",
    "\n",
    "Output format:\n",
    "Return only a valid JSON array, like this:\n",
    "[\n",
    "  {\n",
    "    \"product\": \"product_name\",\n",
    "    \"price\": \"price_value\",\n",
    "    \"quantity\": \"quantity_value\",\n",
    "    \"is_organic\": \"is_organic_value\"\n",
    "  }\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "def clean_input_content(input_content):\n",
    "  cleaned_text = re.sub(r'https?://\\S+|\\[.*?\\]\\((https?://\\S+)\\)', '', input_content)\n",
    "  return cleaned_text.strip()\n",
    "\n",
    "# Format prompt as a list of chat messages\n",
    "def build_prompt(example):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt.strip()},\n",
    "        {\"role\": \"user\", \"content\": clean_input_content(example.get(\"input\", \"\"))}\n",
    "\n",
    "    ]\n",
    "\n",
    "# Format output cleanly as JSON string if possible\n",
    "def format_output(example):\n",
    "    output_data = example.get(\"output\")\n",
    "    if isinstance(output_data, list):\n",
    "        try:\n",
    "            return json.dumps(output_data, indent=2)\n",
    "        except (TypeError, ValueError):\n",
    "            pass\n",
    "    return str(output_data)\n",
    "\n",
    "# Apply transformation\n",
    "dataset_with_prompts = dataset.map(\n",
    "    lambda x: {\n",
    "        \"prompt\": build_prompt(x),\n",
    "        \"answer\": format_output(x),\n",
    "    },\n",
    "    remove_columns=dataset.column_names  # This removes all other fields\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reward Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "similarity_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "UNIT_CONVERSIONS = {\n",
    "    'g': 1, 'gram': 1, 'grams': 1,\n",
    "    'kg': 1000, 'kilogram': 1000, 'kilograms': 1000,\n",
    "    'mg': 0.001, 'milligram': 0.001, 'milligrams': 0.001,\n",
    "    'l': 1000, 'liter': 1000, 'liters': 1000, 'litre': 1000, 'litres': 1000,\n",
    "    'ml': 1, 'milliliter': 1, 'milliliters': 1, 'millilitre': 1, 'millilitres': 1,\n",
    "    'pack': 1, 'packs': 1, 'each': 1, 'unit': 1, 'units': 1\n",
    "}\n",
    "\n",
    "def normalize_price(price_str):\n",
    "    \"\"\"Remove non-numeric characters (except decimal) from price.\"\"\"\n",
    "    if not price_str:\n",
    "        return \"\"\n",
    "    # Remove currency symbols, spaces, and other non-numeric chars\n",
    "    return re.sub(r'[^\\d.]', '', price_str.strip())\n",
    "\n",
    "def parse_quantity(quantity_str):\n",
    "    if not quantity_str:\n",
    "        return None, None\n",
    "    match = re.match(r'^\\s*(\\d*\\.?\\d+)\\s*([a-zA-Z\\-]+)?\\s*$', quantity_str.strip(), re.IGNORECASE)\n",
    "    if not match:\n",
    "        return None, quantity_str.strip()\n",
    "    number = float(match.group(1))\n",
    "    unit = match.group(2).lower() if match.group(2) else None\n",
    "    return number, unit\n",
    "\n",
    "def compare_quantities(pred_quantity, gt_quantity):\n",
    "    pred_number, pred_unit = parse_quantity(pred_quantity)\n",
    "    gt_number, gt_unit = parse_quantity(gt_quantity)\n",
    "    if pred_number is not None and gt_number is not None and pred_unit and gt_unit:\n",
    "        if pred_unit in UNIT_CONVERSIONS and gt_unit in UNIT_CONVERSIONS:\n",
    "            pred_value = pred_number * UNIT_CONVERSIONS[pred_unit]\n",
    "            gt_value = gt_number * UNIT_CONVERSIONS[gt_unit]\n",
    "            if abs(pred_value - gt_value) / max(gt_value, 1e-6) <= 0.01:\n",
    "                return 2.0\n",
    "        return 2.0 * (pred_quantity.strip().lower() == gt_quantity.strip().lower())\n",
    "    if pred_number is not None and gt_number is not None and not pred_unit and not gt_unit:\n",
    "        if abs(pred_number - gt_number) / max(gt_number, 1e-6) <= 0.01:\n",
    "            return 2.0\n",
    "    if pred_number is None and gt_number is None:\n",
    "        return 2.0 * (pred_quantity.strip().lower() == gt_quantity.strip().lower())\n",
    "    return 0.0\n",
    "\n",
    "def item_match_score(gt_item, pred_item):\n",
    "    score = 0.0\n",
    "    pred_product = pred_item.get(\"product\", \"\").strip().lower()\n",
    "    gt_product = gt_item.get(\"product\", \"\").strip().lower()\n",
    "    if pred_product and gt_product:\n",
    "        embeddings = similarity_model.encode([pred_product, gt_product], convert_to_tensor=True)\n",
    "        similarity = util.cos_sim(embeddings[0], embeddings[1]).item()\n",
    "        score += 2.0 * max(0.0, similarity)\n",
    "    if normalize_price(str(pred_item.get(\"price\", \"\"))) == normalize_price(str(gt_item.get(\"price\", \"\"))):\n",
    "        score += 2.0\n",
    "    score += compare_quantities(\n",
    "        str(pred_item.get(\"quantity\", \"\")).strip(),\n",
    "        str(gt_item.get(\"quantity\", \"\")).strip()\n",
    "    )\n",
    "    if str(pred_item.get(\"is_organic\", \"\")).lower() == str(gt_item.get(\"is_organic\", \"\")).lower():\n",
    "        score += 1.0\n",
    "    return score\n",
    "\n",
    "def normalize_ground_truth(answer):\n",
    "    ground_truth = []\n",
    "    if isinstance(answer, dict):\n",
    "        ground_truth = [answer]\n",
    "    elif isinstance(answer, list):\n",
    "        for item in answer:\n",
    "            if isinstance(item, dict):\n",
    "                ground_truth.append(item)\n",
    "            elif isinstance(item, str):\n",
    "                try:\n",
    "                    parsed = json.loads(item)\n",
    "                    if isinstance(parsed, list):\n",
    "                        ground_truth.extend(parsed)\n",
    "                    elif isinstance(parsed, dict):\n",
    "                        ground_truth.append(parsed)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to parse item: {item[:100]}... Error: {e}\")\n",
    "    elif isinstance(answer, str):\n",
    "        try:\n",
    "            parsed = json.loads(answer)\n",
    "            if isinstance(parsed, list):\n",
    "                ground_truth = parsed\n",
    "            elif isinstance(parsed, dict):\n",
    "                ground_truth = [parsed]\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to parse string answer: {e}\")\n",
    "    return ground_truth\n",
    "\n",
    "def parse_prediction(response):\n",
    "    if json is None or not hasattr(json, 'loads'):\n",
    "        raise ImportError(\"json module is not properly imported or has been overwritten\")\n",
    "    if isinstance(response, (list, dict)):\n",
    "        return response\n",
    "    if isinstance(response, str):\n",
    "        try:\n",
    "            cleaned_response = re.sub(r'(?i)^\\s*```?\\s*json\\s*', '', response)\n",
    "            cleaned_response = re.sub(r'\\s*```?\\s*$', '', cleaned_response)\n",
    "            cleaned_response = re.sub(r'}\\s*{', '},{', cleaned_response)\n",
    "            cleaned_response = re.sub(r'\"\\s*[^\"]*?(\"[^\"]*?)?\\s*(\\n\\s*[\\]\\}])', r'\"\"\\2', cleaned_response, flags=re.DOTALL)\n",
    "            if cleaned_response.startswith('[') and not cleaned_response.startswith('[{'):\n",
    "                cleaned_response = re.sub(\n",
    "                    r'^\\[\\s*((?:\"[^\"]*\"\\s*:\\s*\"[^\"]*\"\\s*,?\\s*)+)',\n",
    "                    r'[{\\1}]',\n",
    "                    cleaned_response,\n",
    "                    flags=re.DOTALL\n",
    "                )\n",
    "                cleaned_response = re.sub(\n",
    "                    r'],\\s*((?:\"[^\"]*\"\\s*:\\s*\"[^\"]*\"\\s*,?\\s*)+)',\n",
    "                    r'},{\\1}]',\n",
    "                    cleaned_response,\n",
    "                    flags=re.DOTALL\n",
    "                )\n",
    "                cleaned_response = re.sub(r',\\s*}', '}', cleaned_response)\n",
    "            cleaned_response = re.sub(r'\\]+$', ']', cleaned_response)\n",
    "            cleaned_response = re.sub(r'\\}+$', '}', cleaned_response)\n",
    "            cleaned_response = cleaned_response.encode('ascii', errors='ignore').decode('ascii')\n",
    "            cleaned_response = re.sub(r'}\\s*\\n\\s*\\{', '},\\n{', cleaned_response)\n",
    "            cleaned_response = cleaned_response.strip()\n",
    "            json_match = re.match(r'\\s*\\[.*?\\]\\s*$', cleaned_response, re.DOTALL)\n",
    "            if not json_match:\n",
    "                print(\"No valid JSON array found in cleaned_response\")\n",
    "                return None\n",
    "            if not cleaned_response:\n",
    "                print(\"Cleaned response is empty\")\n",
    "                return None\n",
    "            parsed = json.loads(cleaned_response)\n",
    "            return parsed\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSONDecodeError: Failed to parse cleaned_response: {repr(cleaned_response)[:200]}... Error: {e}\")\n",
    "            char_pos = e.pos if hasattr(e, 'pos') else None\n",
    "            if char_pos:\n",
    "                start = max(0, char_pos - 50)\n",
    "                end = min(len(cleaned_response), char_pos + 50)\n",
    "                print(f\"Context around error (char {char_pos}): {repr(cleaned_response[start:end])}\")\n",
    "            print(f\"Full cleaned_response: {repr(cleaned_response)}\")\n",
    "            try:\n",
    "                if char_pos:\n",
    "                    last_valid = cleaned_response[:char_pos].rfind('}')\n",
    "                    if last_valid != -1:\n",
    "                        fallback_response = cleaned_response[:last_valid + 1] + ']'\n",
    "                        print(f\"Fallback response: {repr(fallback_response)[:200]}...\")\n",
    "                        parsed = json.loads(fallback_response)\n",
    "                        return parsed\n",
    "                    fallback_response = '[]'\n",
    "                    print(f\"Fallback response (empty array): {repr(fallback_response)}\")\n",
    "                    return []\n",
    "            except json.JSONDecodeError as e2:\n",
    "                print(f\"Fallback JSONDecodeError: {repr(fallback_response)[:200]}... Error: {e2}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error parsing response: {repr(response)[:200]}... Error: {e}\")\n",
    "            return None\n",
    "    print(f\"Invalid input type for parse_prediction: {type(response)}\")\n",
    "    return None\n",
    "\n",
    "def structured_data_reward(prompts, completions, answer, **kwargs):\n",
    "    ground_truth = normalize_ground_truth(answer)\n",
    "    if not ground_truth:\n",
    "        return [0.0 for _ in completions]\n",
    "\n",
    "    rewards = []\n",
    "    for completion in completions:\n",
    "        response = completion[0][\"content\"] if completion and isinstance(completion, list) and \"content\" in completion[0] else \"\"\n",
    "        parsed = parse_prediction(response)\n",
    "        if parsed is None:\n",
    "            rewards.append(0.0)\n",
    "            continue\n",
    "\n",
    "        predicted_output = parsed\n",
    "        if isinstance(predicted_output, dict):\n",
    "            predicted_output = [predicted_output]\n",
    "        elif not isinstance(predicted_output, list) or not all(isinstance(item, dict) for item in predicted_output):\n",
    "            rewards.append(0.0)\n",
    "            continue\n",
    "\n",
    "        total_score = 0.0\n",
    "        used_pred_indices = set()\n",
    "        for gt_item in ground_truth:\n",
    "            best_score = 0.0\n",
    "            best_pred_index = None\n",
    "            for idx, pred_item in enumerate(predicted_output):\n",
    "                if idx in used_pred_indices:\n",
    "                    continue\n",
    "                score = item_match_score(gt_item, pred_item)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_pred_index = idx\n",
    "            if best_pred_index is not None:\n",
    "                used_pred_indices.add(best_pred_index)\n",
    "                total_score += best_score\n",
    "\n",
    "        max_score = len(ground_truth) * 7\n",
    "        length_penalty = min(len(predicted_output), len(ground_truth)) / max(len(predicted_output), len(ground_truth), 1)\n",
    "        reward = (total_score / max_score) * length_penalty\n",
    "        rewards.append(max(0.0, min(1.0, reward)))\n",
    "\n",
    "    if rewards:\n",
    "        avg_reward = sum(rewards) / len(rewards)\n",
    "        return [avg_reward] * len(rewards)\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRPO Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prompt_length = 588\n",
    "max_seq_length=2048\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "training_args = GRPOConfig(\n",
    "    learning_rate = 5e-6,\n",
    "    weight_decay = 0.01,\n",
    "    warmup_ratio = 0.2,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    optim = \"adamw_torch_fused\",\n",
    "    logging_steps = 1,\n",
    "    gradient_accumulation_steps = 4, # Increase to 4 for smoother training\n",
    "    num_generations = 4, # Decrease if out of memory\n",
    "    max_prompt_length = max_prompt_length,\n",
    "    max_completion_length = max_seq_length - max_prompt_length,\n",
    "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
    "    max_steps = 1000,\n",
    "    save_steps = 250,\n",
    "    max_grad_norm = 1.0,\n",
    "    num_train_epochs=1,\n",
    "    report_to = \"none\", # Can use Weights & Biases\n",
    "    output_dir = \"outputs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs = [structured_data_reward],\n",
    "    args = training_args,\n",
    "    train_dataset = dataset_with_prompts,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = \"./finetuned_model\"\n",
    "\n",
    "# Save LoRA adapters (recommended for efficiency)\n",
    "model.save_pretrained(save_directory)  # Saves LoRA adapters\n",
    "tokenizer.save_pretrained(save_directory)  # Saves tokenizer\n",
    "\n",
    "# Optional: Save merged model (base model + LoRA adapters)\n",
    "model.save_pretrained_merged(save_directory, tokenizer, save_method=\"merged_16bit\")  # Merges to 16-bit precision\n",
    "\n",
    "# Save trainer state (for resuming training)\n",
    "trainer.save_model(save_directory)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
